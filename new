we have 3 phases in a module 
1. Using additional LLMS and python libraries we are extracting the different score as per the Recomended metrics for the use case like subjective like completeness, truthfulness etc / objective like Bleu, meteor, ter, bert etc/ safety like haluzination, toxicity, Bias etc
2. Using open ai with the concept of chain poll. That goes through the series of interrogation with the model's own response and creates a score.
3. Score Aggregator module : this module internally uses Completions open ai, combines both the Point 1 and 2 outputs and then generates a score for each metrics. But here the module will have more priority on the metrics calculation. 

this module is a part of my patent that I am filing
give me a nice write up everything should be non-obvious
